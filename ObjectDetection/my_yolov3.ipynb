{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde6c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881d1075-432f-4150-9cdb-a8cbb28c634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "IMAGE_SIZE = 416\n",
    "BATCH_SIZE = 10\n",
    "data_dir = '../data/IndoorObjectsDetection'\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077e5acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'door',\n",
       " 1: 'cabinetDoor',\n",
       " 2: 'refrigeratorDoor',\n",
       " 3: 'window',\n",
       " 4: 'chair',\n",
       " 5: 'table',\n",
       " 6: 'cabinet',\n",
       " 7: 'couch',\n",
       " 8: 'openedDoor',\n",
       " 9: 'pole'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import random\n",
    "\n",
    "data_config = open( data_dir + '/data.yaml')\n",
    "\n",
    "data_info = yaml.load(data_config, Loader=yaml.FullLoader)\n",
    "\n",
    "train_data_path = data_info['train_data_path']\n",
    "val_data_path = data_info['val_data_path']\n",
    "test_data_path = data_info['test_data_path']\n",
    "\n",
    "train_labels_path = data_info['train_labels_path']\n",
    "val_labels_path = data_info['val_labels_path']\n",
    "test_labels_path = data_info['test_labels_path']\n",
    "\n",
    "target_list = data_info['names']\n",
    "target_dict = dict(zip(range(len(target_list)), target_list))\n",
    "\n",
    "target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a21b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 3, 416, 416])\n",
      "torch.Size([1, 512, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained = False)\n",
    "layers = [m for m in resnet18.children()]\n",
    "\n",
    "# 마지막 2층인 average pooling & fully connected layer 은 back bone으로 사용하지 않음\n",
    "test_net = nn.Sequential(*layers[:-2]) \n",
    "\n",
    "temp_x = torch.randn(1,3,IMAGE_SIZE,IMAGE_SIZE)\n",
    "temp_y = test_net(temp_x)\n",
    "\n",
    "\n",
    "print(type(temp_x))\n",
    "print(temp_x.shape)\n",
    "print(temp_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcc8e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass YOLOv1_RESNET(nn.Module):\\n    def __init__(self, num_classes):\\n        super().__init__()\\n        \\n        self.num_classes = num_classes\\n        self.num_bboxes = 2\\n        self.grid_size = 7\\n        \\n        resnet18 = torchvision.models.resnet18(pretrained = False)\\n        layers = [m for m in resnet18.children()]\\n        \\n        self.backbone = nn.Sequential(*layers[:-2])\\n        \\n        self.neck = nn.Sequential(\\n            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, padding=0, bias=False),\\n            nn.BatchNorm2d(1024),\\n            nn.ReLU(inplace=True),\\n            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1, bias=False),\\n            nn.BatchNorm2d(1024),\\n            nn.ReLU(inplace=True),\\n            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1, bias=False),\\n            nn.BatchNorm2d(1024),\\n            nn.ReLU(inplace=True)\\n        )\\n        \\n        self.head = nn.Sequential(\\n            nn.Conv2d(in_channels=1024, out_channels=5*self.num_bboxes+self.num_classes, kernel_size=1, padding=0, bias=False),\\n            nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\\n        )\\n        \\n    def forward(self, x):\\n        out = self.backbone(x)\\n        out = self.neck(out)\\n        out = self.head(out)\\n        return out\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class YOLOv1_RESNET(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "        \n",
    "        resnet18 = torchvision.models.resnet18(pretrained = False)\n",
    "        layers = [m for m in resnet18.children()]\n",
    "        \n",
    "        self.backbone = nn.Sequential(*layers[:-2])\n",
    "        \n",
    "        self.neck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=5*self.num_bboxes+self.num_classes, kernel_size=1, padding=0, bias=False),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.neck(out)\n",
    "        out = self.head(out)\n",
    "        return out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f925b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNUM_CLASSES = len(target_list)\\nmodel = YOLOv1_RESNET(num_classes = NUM_CLASSES)\\n\\nmodel\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NUM_CLASSES = len(target_list)\n",
    "model = YOLOv1_RESNET(num_classes = NUM_CLASSES)\n",
    "\n",
    "model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de2de4-a6f5-4dd9-97c0-4ae74f30206c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02020a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detection_dataset():\n",
    "    def __init__(self, data_dir, phase, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.phase = phase\n",
    "        self.image_files = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        for fn in os.listdir(os.path.join(self.data_dir, phase, 'images')):\n",
    "            bboxes, class_ids = self.get_label(fn)\n",
    "                                \n",
    "            if(fn.endswith(\"jpg\") and bboxes.size != 0 and class_ids.size != 0):\n",
    "                self.image_files.append(fn)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, image = self.get_image(index)\n",
    "        bboxes, class_ids = self.get_label(filename)\n",
    "        \n",
    "        if self.transform: \n",
    "            transformed_data = self.transform(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "            image = transformed_data['image']\n",
    "            bboxes = np.array(transformed_data['bboxes'])\n",
    "            class_ids = np.array(transformed_data['class_ids'])\n",
    "        else:\n",
    "            #transform 을 하지 않을경우 reshape to (C,W,H)\n",
    "            image = torch.Tensor(image).permute(2,0,1)\n",
    "        \n",
    "        target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)    \n",
    "        return image, target, filename\n",
    "    \n",
    "    def get_image(self, index):\n",
    "        filename = self.image_files[index]\n",
    "        image_path = os.path.join(self.data_dir, self.phase, 'images', filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        return filename, image\n",
    "    \n",
    "    \n",
    "    def get_label(self, filename):\n",
    "        image_id = filename.split('.')[0]\n",
    "        label_file_path = os.path.join(self.data_dir, self.phase, 'labels') + '/' + image_id + '.txt'\n",
    "        try:\n",
    "            bbox_df = pd.read_csv(label_file_path, sep=' ', header=None)\n",
    "\n",
    "            # width or height 가 0이면 제거 \n",
    "            bbox_df = bbox_df[(bbox_df[3] != 0) & (bbox_df[4] != 0)]\n",
    "            \n",
    "            bboxes = np.asarray(bbox_df[[1,2,3,4]])\n",
    "            class_ids = np.asarray(bbox_df[0])\n",
    "            \n",
    "        except Exception as e:\n",
    "            bboxes = np.array([])\n",
    "            class_ids = np.array([])\n",
    "            \n",
    "            \n",
    "        return bboxes, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcf18cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose([\n",
       "  Resize(p=1.0, height=416, width=416, interpolation=1),\n",
       "  Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, normalization='standard'),\n",
       "  ToTensorV2(p=1.0, transpose_mask=False),\n",
       "], p=1.0, bbox_params={'format': 'yolo', 'label_fields': ['class_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\"\"\"\n",
    "    when you use yolo format bbox param\n",
    "    need to add logic in albumentations/augmentations/bbox_utils.py - check_bbox() method\n",
    "    to make bbox boundery in [0,1]\n",
    "    \n",
    "    -------------------\n",
    "    bbox=list(bbox)\n",
    "    \n",
    "    for i in range(4):\n",
    "      if (bbox[i]<0) :\n",
    "        bbox[i]=0\n",
    "      elif (bbox[i]>1) :\n",
    "        bbox[i]=1\n",
    "    \n",
    "    bbox=tuple(bbox)\n",
    "    --------------------\n",
    "\"\"\"\n",
    "\n",
    "#mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225) -> imageNet 데이터셋에 기반한 계산된 수치 \n",
    "transform = A.Compose([\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        # A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0c4207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73510099e0f94131ac4f4b34683c90cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=860), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from my_util import set_bounding_boxes, set_bounding_box, get_random_color_dict\n",
    "from ipywidgets import interact\n",
    "\n",
    "transformed_train_dataset = Detection_dataset(data_dir='../data/IndoorObjectsDetection', phase=\"train\", transform=transform)\n",
    "\n",
    "@interact(index=(0, len(transformed_train_dataset)-1))\n",
    "def show_transformed_image(index=0):\n",
    "    img, target, filename = transformed_train_dataset[index]\n",
    "    \n",
    "    np_image = make_grid(img, normalize=True).permute(1,2,0).numpy()\n",
    "    np_image_unit8 = (np_image*255).astype(np.uint8)\n",
    "    \n",
    "    res = set_bounding_boxes(np_image_unit8, target[:,0:4], 'yolo', target[:,4].astype(int), target_dict, get_random_color_dict(target_dict))\n",
    "    plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe4aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "        \n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n",
    "\n",
    "def train_valid_dataloader(data_dir, batch_size=4, transform=None):\n",
    "    dataloaders = {}\n",
    "    \n",
    "    train_dataset = Detection_dataset(data_dir=data_dir, phase=\"train\", transform=transform)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    valid_dataset = Detection_dataset(data_dir=data_dir, phase=\"valid\", transform=transform)    \n",
    "    dataloaders[\"val\"] = DataLoader(valid_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "dataloaders = train_valid_dataloader(data_dir, BATCH_SIZE, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119930c0-3296-41da-a217-3d6fa5e4ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npip install --trusted-host pypi.python.org --trusted-host pypi.org --trusted-host files.pythonhosted.org tqdm\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pip install --trusted-host pypi.python.org --trusted-host pypi.org --trusted-host files.pythonhosted.org tqdm\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb81364-0e19-48b0-a177-41bdd67bad15",
   "metadata": {},
   "source": [
    "# **YOLO_V3 Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e935a945-f31e-489f-9eac-8d3ee0cdbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=(kernel_size-1)//2, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34287db5-5f0c-4869-aafd-fcefd826848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backbone\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            BasicConvBlock(channels, channels//2, kernel_size=1, stride=1),\n",
    "            BasicConvBlock(channels//2, channels, kernel_size=3, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.residual(x) + x\n",
    "\n",
    "class DarkNet53(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = BasicConvBlock(3, 32, 3, 1)\n",
    "        self.block1 = nn.Sequential(\n",
    "            BasicConvBlock(32, 64, 3, 2),\n",
    "            ResidualBlock(64)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            BasicConvBlock(64, 128, 3, 2),\n",
    "            nn.Sequential(*[ResidualBlock(128) for _ in range(2)])\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            BasicConvBlock(128, 256, 3, 2),\n",
    "            nn.Sequential(*[ResidualBlock(256) for _ in range(8)])\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            BasicConvBlock(256, 512, 3, 2),\n",
    "            nn.Sequential(*[ResidualBlock(512) for _ in range(8)])\n",
    "        )\n",
    "        self.block5 = nn.Sequential(\n",
    "            BasicConvBlock(512, 1024, 3, 2),\n",
    "            nn.Sequential(*[ResidualBlock(1024) for _ in range(4)])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        feature_map1 = self.block3(x)\n",
    "        feature_map2 = self.block4(feature_map1)\n",
    "        feature_map3 = self.block5(feature_map2)\n",
    "\n",
    "        return feature_map1, feature_map2, feature_map3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d4016d-ce05-4a19-acac-55cf19ce00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neck : FPN top-down\n",
    "class FPN_featureBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            BasicConvBlock(in_channels, out_channels, 1),\n",
    "            BasicConvBlock(out_channels, out_channels*2, 3),\n",
    "            BasicConvBlock(out_channels*2, out_channels, 1),\n",
    "            BasicConvBlock(out_channels, out_channels*2, 3),\n",
    "            BasicConvBlock(out_channels*2, out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "        \n",
    "class UpSampling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            BasicConvBlock(in_channels, out_channels, 1),\n",
    "            nn.Upsample(scale_factor = 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.upsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8bb601a-7291-4563-8f78-a816716d2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Head\n",
    "class DetectionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, anchors, num_classes, img_size=IMAGE_SIZE):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pred = nn.Sequential(\n",
    "            BasicConvBlock(in_channels, in_channels*2, 3),\n",
    "            nn.Conv2d(in_channels*2, (num_classes+5)*3, 1)\n",
    "        )\n",
    "        self.anchors = anchors\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        grid_size = x.size(2)\n",
    "        \n",
    "        output = self.pred(x)\n",
    "        output = output.view(batch_size, 3, self.num_classes+5, grid_size, grid_size) \n",
    "        output = output.permute(0, 1, 3, 4, 2)\n",
    "\n",
    "        output = output.contiguous()\n",
    "\n",
    "        # 추가 처리 필요\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "febfb77d-ab9d-4b82-91fe-7d4565ab6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolov3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.darknet53 = DarkNet53()\n",
    "\n",
    "        self.fpn_feature_block1 = FPN_featureBlock(1024, 512)\n",
    "        self.detectionlayer1 = DetectionLayer(512, num_classes)\n",
    "        self.upsampling1 = UpSampling(512, 256)\n",
    "\n",
    "        self.fpn_feature_block2 = FPN_featureBlock(512+256, 256)\n",
    "        self.detectionlayer2 = DetectionLayer(256, num_classes)\n",
    "        self.upsampling2 = UpSampling(256, 128)\n",
    "        \n",
    "        self.fpn_feature_block3 = FPN_featureBlock(256+128, 128)\n",
    "        self.detectionlayer3 = DetectionLayer(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.feature1, self.feature2, self.feature3 = self.darknet53(x)\n",
    "        \n",
    "        x = self.fpn_feature_block1(self.feature3)\n",
    "        output1 = self.detectionlayer1(x)\n",
    "        x = self.upsampling1(x)\n",
    "\n",
    "        x = self.fpn_feature_block2(torch.cat([x, self.feature2], dim=1))\n",
    "        output2 = self.detectionlayer2(x)\n",
    "        x = self.upsampling2(x)\n",
    "\n",
    "        x = self.fpn_feature_block3(torch.cat([x, self.feature1], dim=1))\n",
    "        output3 = self.detectionlayer3(x)\n",
    "\n",
    "        return output1, output2, output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f57f988f-b3ea-42f0-85b6-5c5d7b5a0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 13, 13, 25])\n",
      "torch.Size([1, 3, 26, 26, 25])\n",
      "torch.Size([1, 3, 52, 52, 25])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1, 3, 416, 416))\n",
    "model = Yolov3(num_classes = 20).to(device)\n",
    "out = model(x)\n",
    "print(out[0].shape) # torch.Size([1, 3, 13, 13, 25])\n",
    "print(out[1].shape) # torch.Size([1, 3, 26, 26, 25])\n",
    "print(out[2].shape) # torch.Size([1, 3, 52, 52, 25]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ca1fd9-9743-4121-975d-9fe613067b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "Yolov3                                                       [1, 3, 13, 13, 25]        --\n",
       "├─DarkNet53: 1-1                                             [1, 256, 52, 52]          --\n",
       "│    └─BasicConvBlock: 2-1                                   [1, 32, 416, 416]         --\n",
       "│    │    └─Sequential: 3-1                                  [1, 32, 416, 416]         928\n",
       "│    └─Sequential: 2-2                                       [1, 64, 208, 208]         --\n",
       "│    │    └─BasicConvBlock: 3-2                              [1, 64, 208, 208]         18,560\n",
       "│    │    └─ResidualBlock: 3-3                               [1, 64, 208, 208]         20,672\n",
       "│    └─Sequential: 2-3                                       [1, 128, 104, 104]        --\n",
       "│    │    └─BasicConvBlock: 3-4                              [1, 128, 104, 104]        73,984\n",
       "│    │    └─Sequential: 3-5                                  [1, 128, 104, 104]        164,608\n",
       "│    └─Sequential: 2-4                                       [1, 256, 52, 52]          --\n",
       "│    │    └─BasicConvBlock: 3-6                              [1, 256, 52, 52]          295,424\n",
       "│    │    └─Sequential: 3-7                                  [1, 256, 52, 52]          2,627,584\n",
       "│    └─Sequential: 2-5                                       [1, 512, 26, 26]          --\n",
       "│    │    └─BasicConvBlock: 3-8                              [1, 512, 26, 26]          1,180,672\n",
       "│    │    └─Sequential: 3-9                                  [1, 512, 26, 26]          10,498,048\n",
       "│    └─Sequential: 2-6                                       [1, 1024, 13, 13]         --\n",
       "│    │    └─BasicConvBlock: 3-10                             [1, 1024, 13, 13]         4,720,640\n",
       "│    │    └─Sequential: 3-11                                 [1, 1024, 13, 13]         20,983,808\n",
       "├─FPN_featureBlock: 1-2                                      [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-7                                       [1, 512, 13, 13]          --\n",
       "│    │    └─BasicConvBlock: 3-12                             [1, 512, 13, 13]          525,312\n",
       "│    │    └─BasicConvBlock: 3-13                             [1, 1024, 13, 13]         4,720,640\n",
       "│    │    └─BasicConvBlock: 3-14                             [1, 512, 13, 13]          525,312\n",
       "│    │    └─BasicConvBlock: 3-15                             [1, 1024, 13, 13]         4,720,640\n",
       "│    │    └─BasicConvBlock: 3-16                             [1, 512, 13, 13]          525,312\n",
       "├─DetectionLayer: 1-3                                        [1, 3, 13, 13, 25]        --\n",
       "│    └─Sequential: 2-8                                       [1, 75, 13, 13]           --\n",
       "│    │    └─BasicConvBlock: 3-17                             [1, 1024, 13, 13]         4,720,640\n",
       "│    │    └─Conv2d: 3-18                                     [1, 75, 13, 13]           76,875\n",
       "├─UpSampling: 1-4                                            [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-9                                       [1, 256, 26, 26]          --\n",
       "│    │    └─BasicConvBlock: 3-19                             [1, 256, 13, 13]          131,584\n",
       "│    │    └─Upsample: 3-20                                   [1, 256, 26, 26]          --\n",
       "├─FPN_featureBlock: 1-5                                      [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-10                                      [1, 256, 26, 26]          --\n",
       "│    │    └─BasicConvBlock: 3-21                             [1, 256, 26, 26]          197,120\n",
       "│    │    └─BasicConvBlock: 3-22                             [1, 512, 26, 26]          1,180,672\n",
       "│    │    └─BasicConvBlock: 3-23                             [1, 256, 26, 26]          131,584\n",
       "│    │    └─BasicConvBlock: 3-24                             [1, 512, 26, 26]          1,180,672\n",
       "│    │    └─BasicConvBlock: 3-25                             [1, 256, 26, 26]          131,584\n",
       "├─DetectionLayer: 1-6                                        [1, 3, 26, 26, 25]        --\n",
       "│    └─Sequential: 2-11                                      [1, 75, 26, 26]           --\n",
       "│    │    └─BasicConvBlock: 3-26                             [1, 512, 26, 26]          1,180,672\n",
       "│    │    └─Conv2d: 3-27                                     [1, 75, 26, 26]           38,475\n",
       "├─UpSampling: 1-7                                            [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-12                                      [1, 128, 52, 52]          --\n",
       "│    │    └─BasicConvBlock: 3-28                             [1, 128, 26, 26]          33,024\n",
       "│    │    └─Upsample: 3-29                                   [1, 128, 52, 52]          --\n",
       "├─FPN_featureBlock: 1-8                                      [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-13                                      [1, 128, 52, 52]          --\n",
       "│    │    └─BasicConvBlock: 3-30                             [1, 128, 52, 52]          49,408\n",
       "│    │    └─BasicConvBlock: 3-31                             [1, 256, 52, 52]          295,424\n",
       "│    │    └─BasicConvBlock: 3-32                             [1, 128, 52, 52]          33,024\n",
       "│    │    └─BasicConvBlock: 3-33                             [1, 256, 52, 52]          295,424\n",
       "│    │    └─BasicConvBlock: 3-34                             [1, 128, 52, 52]          33,024\n",
       "├─DetectionLayer: 1-9                                        [1, 3, 52, 52, 25]        --\n",
       "│    └─Sequential: 2-14                                      [1, 75, 52, 52]           --\n",
       "│    │    └─BasicConvBlock: 3-35                             [1, 256, 52, 52]          295,424\n",
       "│    │    └─Conv2d: 3-36                                     [1, 75, 52, 52]           19,275\n",
       "==============================================================================================================\n",
       "Total params: 61,626,049\n",
       "Trainable params: 61,626,049\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 32.71\n",
       "==============================================================================================================\n",
       "Input size (MB): 2.08\n",
       "Forward/backward pass size (MB): 614.75\n",
       "Params size (MB): 246.50\n",
       "Estimated Total Size (MB): 863.33\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size = (1, 3, 416, 416), device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2011e293-3bf9-415d-a359-3467a2d56024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yolov3(\n",
       "  (darknet53): DarkNet53(\n",
       "    (conv1): BasicConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block1): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (residual): Sequential(\n",
       "          (0): BasicConvBlock(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicConvBlock(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block5): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicConvBlock(\n",
       "              (conv): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fpn_feature_block1): FPN_featureBlock(\n",
       "    (conv): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (detectionlayer1): DetectionLayer(\n",
       "    (pred): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2d(1024, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (upsampling1): UpSampling(\n",
       "    (upsample): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    )\n",
       "  )\n",
       "  (fpn_feature_block2): FPN_featureBlock(\n",
       "    (conv): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (detectionlayer2): DetectionLayer(\n",
       "    (pred): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2d(512, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (upsampling2): UpSampling(\n",
       "    (upsample): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    )\n",
       "  )\n",
       "  (fpn_feature_block3): FPN_featureBlock(\n",
       "    (conv): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (detectionlayer3): DetectionLayer(\n",
       "    (pred): Sequential(\n",
       "      (0): BasicConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9e318-6f8c-4a08-bd36-be4ca323133c",
   "metadata": {},
   "source": [
    "# **YOLO_V3 Loss** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "180ec3c6-0e82-445a-ad44-131773ec1ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.6400,  2.8600],\n",
       "         [ 4.9400,  6.2400],\n",
       "         [11.7000, 10.1400]],\n",
       "\n",
       "        [[ 1.8200,  3.9000],\n",
       "         [ 3.9000,  2.8600],\n",
       "         [ 3.6400,  7.5400]],\n",
       "\n",
       "        [[ 1.0400,  1.5600],\n",
       "         [ 2.0800,  3.6400],\n",
       "         [ 4.1600,  3.1200]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMAGE_SIZE\n",
    "# Anchor boxes for each feature map scaled between 0 and 1 \n",
    "# 3 feature maps at 3 different scales based on YOLOv3 paper \n",
    "ANCHORS = [ \n",
    "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)], \n",
    "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)], \n",
    "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)], \n",
    "] \n",
    "\n",
    "GRID_SIZE = [IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8] # [13, 26, 52]\n",
    "\n",
    "scaled_anchors = ( \n",
    "    torch.tensor(ANCHORS) * torch.tensor(GRID_SIZE).unsqueeze(1).unsqueeze(1).repeat(1,3,2) \n",
    ")\n",
    "\n",
    "scaled_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90505607-27fa-4887-8308-b13b83660896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate Intersection over Union (IoU) \n",
    "def iou(box1, box2):\n",
    "    # IoU score for prediction and label \n",
    "    # box1 (prediction) and box2 (label) are both in [x, y, width, height] format \n",
    "      \n",
    "    # Box coordinates of prediction \n",
    "    b1_x1 = box1[..., 0:1] - box1[..., 2:3] / 2\n",
    "    b1_y1 = box1[..., 1:2] - box1[..., 3:4] / 2\n",
    "    b1_x2 = box1[..., 0:1] + box1[..., 2:3] / 2\n",
    "    b1_y2 = box1[..., 1:2] + box1[..., 3:4] / 2\n",
    "\n",
    "    # Box coordinates of ground truth \n",
    "    b2_x1 = box2[..., 0:1] - box2[..., 2:3] / 2\n",
    "    b2_y1 = box2[..., 1:2] - box2[..., 3:4] / 2\n",
    "    b2_x2 = box2[..., 0:1] + box2[..., 2:3] / 2\n",
    "    b2_y2 = box2[..., 1:2] + box2[..., 3:4] / 2\n",
    "\n",
    "    # Get the coordinates of the intersection rectangle \n",
    "    x1 = torch.max(b1_x1, b2_x1) \n",
    "    y1 = torch.max(b1_y1, b2_y1) \n",
    "    x2 = torch.min(b1_x2, b2_x2) \n",
    "    y2 = torch.min(b1_y2, b2_y2) \n",
    "    # Make sure the intersection is at least 0 \n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0) \n",
    "\n",
    "    # Calculate the union area \n",
    "    box1_area = abs((b1_x2 - b1_x1) * (b1_y2 - b1_y1)) \n",
    "    box2_area = abs((b2_x2 - b2_x1) * (b2_y2 - b2_y1)) \n",
    "    union = box1_area + box2_area - intersection \n",
    "\n",
    "    # Calculate the IoU score \n",
    "    epsilon = 1e-6\n",
    "    iou_score = intersection / (union + epsilon) \n",
    "\n",
    "    # Return IoU score \n",
    "    return iou_score \n",
    "\n",
    "def iouOnWH(box1, box2):  \n",
    "    # box1:bbox WH, box2:anchors WH\n",
    "    # Calculate intersection area \n",
    "    intersection_area = torch.min(box1[..., 0], box2[..., 0]) * torch.min(box1[..., 1], box2[..., 1]) \n",
    "\n",
    "    # Calculate union area \n",
    "    box1_area = box1[0] * box1[1] \n",
    "    box2_area = box2[..., 0] * box2[..., 1] \n",
    "    union_area = box1_area + box2_area - intersection_area \n",
    "\n",
    "    # Calculate IoU score \n",
    "    iou_score = intersection_area / union_area \n",
    "\n",
    "    # Return IoU score \n",
    "    return iou_score\n",
    "\n",
    "class YOLOLoss(nn.Module): \n",
    "    def __init__(self): \n",
    "        super().__init__() \n",
    "        self.mse = nn.MSELoss() \n",
    "        self.bce = nn.BCEWithLogitsLoss() \n",
    "        self.cross_entropy = nn.CrossEntropyLoss() \n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "      \n",
    "    def forward(self, pred, target, anchors): \n",
    "        # Identifying which cells in target have objects  \n",
    "        # and which have no objects \n",
    "        obj = target[..., 0] == 1\n",
    "        no_obj = target[..., 0] == 0\n",
    "  \n",
    "        # Calculating No object loss \n",
    "        no_object_loss = self.bce( \n",
    "            (pred[..., 0:1][no_obj]), (target[..., 0:1][no_obj]), \n",
    "        ) \n",
    "  \n",
    "          \n",
    "        # Reshaping anchors to match predictions \n",
    "        anchors = anchors.reshape(1, 3, 1, 1, 2) \n",
    "        # Box prediction confidence \n",
    "        box_preds = torch.cat([self.sigmoid(pred[..., 1:3]), \n",
    "                               torch.exp(pred[..., 3:5]) * anchors \n",
    "                            ],dim=-1) \n",
    "        # Calculating intersection over union for prediction and target \n",
    "        ious = iou(box_preds[obj], target[..., 1:5][obj]).detach() \n",
    "        # Calculating Object loss \n",
    "        object_loss = self.mse(self.sigmoid(pred[..., 0:1][obj]), \n",
    "                               ious * target[..., 0:1][obj]) \n",
    "  \n",
    "          \n",
    "        # Predicted box coordinates \n",
    "        pred[..., 1:3] = self.sigmoid(pred[..., 1:3]) \n",
    "        # Target box coordinates \n",
    "        target[..., 3:5] = torch.log(1e-6 + target[..., 3:5] / anchors) \n",
    "        # Calculating box coordinate loss \n",
    "        box_loss = self.mse(pred[..., 1:5][obj], \n",
    "                            target[..., 1:5][obj]) \n",
    "  \n",
    "          \n",
    "        # Claculating class loss \n",
    "        class_loss = self.cross_entropy((pred[..., 5:][obj]), \n",
    "                                   target[..., 5][obj].long()) \n",
    "  \n",
    "        # Total loss \n",
    "        return ( \n",
    "            box_loss \n",
    "            + object_loss \n",
    "            + no_object_loss \n",
    "            + class_loss \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46bbbfbb-1833-4e1e-825f-588c5e005e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define the train function to train the model \n",
    "def training_loop(loader, model, optimizer, loss_fn, scaler, scaled_anchors): \n",
    "    # Creating a progress bar \n",
    "    progress_bar = tqdm(loader, leave=True) \n",
    "  \n",
    "    # Initializing a list to store the losses \n",
    "    losses = [] \n",
    "  \n",
    "    # Iterating over the training data \n",
    "    for _, (x, y, filename) in enumerate(progress_bar): \n",
    "        x = x.to(device) \n",
    "\n",
    "        y0, y1, y2 = ( \n",
    "            y[0].to(device), \n",
    "            y[1].to(device), \n",
    "            y[2].to(device), \n",
    "        ) \n",
    "  \n",
    "        with torch.cuda.amp.autocast(): \n",
    "            # Getting the model predictions \n",
    "            feature_map1, feature_map2, feature_map3 = model(x) \n",
    "            # Calculating the loss at each scale \n",
    "            loss = ( \n",
    "                  loss_fn(feature_map1, y0, scaled_anchors[0]) \n",
    "                + loss_fn(feature_map2, y1, scaled_anchors[1]) \n",
    "                + loss_fn(feature_map3, y2, scaled_anchors[2]) \n",
    "            ) \n",
    "  \n",
    "        # Add the loss to the list \n",
    "        losses.append(loss.item()) \n",
    "  \n",
    "        # Reset gradients \n",
    "        optimizer.zero_grad() \n",
    "  \n",
    "        # Backpropagate the loss \n",
    "        scaler.scale(loss).backward() \n",
    "  \n",
    "        # Optimization step \n",
    "        scaler.step(optimizer) \n",
    "  \n",
    "        # Update the scaler for next iteration \n",
    "        scaler.update() \n",
    "  \n",
    "        # update progress bar with loss \n",
    "        mean_loss = sum(losses) / len(losses) \n",
    "        progress_bar.set_postfix(loss=mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc8dff7f-b650-455b-aa62-e138a4c5a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/87 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x ->  tensor([[[[ 1.0673,  1.0844,  1.0844,  ...,  0.8447,  0.8618,  0.8618],\n",
      "          [ 1.0844,  1.0844,  1.0844,  ...,  0.8447,  0.8447,  0.8447],\n",
      "          [ 1.0844,  1.0844,  1.1015,  ...,  0.8447,  0.8276,  0.8276],\n",
      "          ...,\n",
      "          [ 0.9817,  0.9646,  0.9646,  ..., -1.7583, -1.6384, -1.2788],\n",
      "          [ 0.9817,  0.9988,  0.9817,  ..., -1.6727, -1.6555, -1.5699],\n",
      "          [ 0.9817,  0.9988,  0.9817,  ..., -1.2617, -1.2617, -1.2103]],\n",
      "\n",
      "         [[ 1.0630,  1.0805,  1.0805,  ...,  1.1155,  1.1331,  1.1331],\n",
      "          [ 1.0805,  1.0805,  1.0805,  ...,  1.1155,  1.1155,  1.1155],\n",
      "          [ 1.0630,  1.0630,  1.0630,  ...,  1.1155,  1.0980,  1.0980],\n",
      "          ...,\n",
      "          [ 0.8704,  0.8529,  0.8704,  ..., -1.6856, -1.5280, -1.1604],\n",
      "          [ 0.8880,  0.8880,  0.8704,  ..., -1.5630, -1.5455, -1.4755],\n",
      "          [ 0.8880,  0.8880,  0.8704,  ..., -1.1429, -1.1429, -1.0903]],\n",
      "\n",
      "         [[ 0.7054,  0.7228,  0.7228,  ...,  1.3851,  1.4025,  1.4025],\n",
      "          [ 0.7228,  0.7228,  0.7228,  ...,  1.3851,  1.3851,  1.3851],\n",
      "          [ 0.7576,  0.7576,  0.7751,  ...,  1.3851,  1.3677,  1.3677],\n",
      "          ...,\n",
      "          [ 0.3568,  0.3742,  0.4091,  ..., -1.4907, -1.3339, -0.9678],\n",
      "          [ 0.3742,  0.4265,  0.4091,  ..., -1.3687, -1.3513, -1.2641],\n",
      "          [ 0.3742,  0.4265,  0.4091,  ..., -0.9504, -0.9504, -0.8981]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.4397, -0.3883, -0.3198,  ...,  0.0227, -0.2171,  0.0569],\n",
      "          [-0.4054, -0.2684, -0.2171,  ..., -0.0116,  0.0569, -0.0629],\n",
      "          [-0.4397, -0.3541, -0.4739,  ..., -0.2342,  0.0741,  0.1768],\n",
      "          ...,\n",
      "          [-0.7479, -0.5424, -0.6281,  ...,  0.4508,  0.5022,  0.4679],\n",
      "          [-0.4911, -0.6794, -1.0219,  ...,  0.5193,  0.4337,  0.5193],\n",
      "          [-1.0733, -0.6452, -0.5767,  ...,  0.5707,  0.5878,  0.4508]],\n",
      "\n",
      "         [[-0.0224,  0.0301,  0.1001,  ...,  0.4153,  0.1702,  0.4153],\n",
      "          [ 0.0126,  0.1527,  0.2227,  ...,  0.3803,  0.4503,  0.2927],\n",
      "          [-0.0224,  0.0651, -0.0574,  ...,  0.1877,  0.5028,  0.5728],\n",
      "          ...,\n",
      "          [-0.1450,  0.0651, -0.0224,  ...,  0.7654,  0.8179,  0.8004],\n",
      "          [ 0.1352, -0.0574, -0.4076,  ...,  0.8354,  0.7479,  0.8529],\n",
      "          [-0.4251, -0.0224, -0.0049,  ...,  0.8354,  0.8529,  0.7479]],\n",
      "\n",
      "         [[ 0.2522,  0.3045,  0.3742,  ...,  0.6705,  0.4265,  0.6705],\n",
      "          [ 0.2871,  0.4265,  0.4962,  ...,  0.6356,  0.7054,  0.5485],\n",
      "          [ 0.2348,  0.3219,  0.2173,  ...,  0.4614,  0.7751,  0.8448],\n",
      "          ...,\n",
      "          [ 0.3219,  0.5311,  0.4439,  ...,  0.8797,  0.9319,  0.8797],\n",
      "          [ 0.6008,  0.4091,  0.0605,  ...,  0.9494,  0.8622,  0.9494],\n",
      "          [ 0.0605,  0.4614,  0.4962,  ...,  0.9668,  0.9842,  0.8622]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.1700,  0.9817,  0.9817,  ...,  0.4166,  0.3652,  0.2796],\n",
      "          [ 1.1700,  1.0331,  1.0673,  ...,  0.5536,  0.4508,  0.3994],\n",
      "          [ 1.1872,  1.0502,  1.0502,  ...,  0.5707,  0.5536,  0.5536],\n",
      "          ...,\n",
      "          [-1.9809, -1.9980, -1.9467,  ..., -1.8610, -1.8268, -1.7925],\n",
      "          [-1.9638, -1.9467, -1.8439,  ..., -1.8782, -1.8439, -1.8268],\n",
      "          [-1.9638, -1.8439, -1.6727,  ..., -1.9124, -1.8953, -1.9295]],\n",
      "\n",
      "         [[ 0.9580,  0.7829,  0.8004,  ...,  0.5378,  0.6254,  0.6254],\n",
      "          [ 0.9930,  0.8354,  0.8529,  ...,  0.6254,  0.6604,  0.6779],\n",
      "          [ 0.9930,  0.8529,  0.7829,  ...,  0.5728,  0.6429,  0.6779],\n",
      "          ...,\n",
      "          [-1.0028, -1.0728, -1.0728,  ..., -0.9153, -0.8978, -0.8803],\n",
      "          [-0.9853, -1.0028, -0.9678,  ..., -0.9328, -0.8627, -0.8277],\n",
      "          [-0.9853, -0.9328, -0.8277,  ..., -0.9503, -0.8803, -0.8978]],\n",
      "\n",
      "         [[ 1.0365,  0.7925,  0.7751,  ...,  0.8971,  1.1411,  1.2631],\n",
      "          [ 1.0714,  0.8448,  0.8099,  ...,  0.8971,  1.0539,  1.1237],\n",
      "          [ 1.0714,  0.8622,  0.7402,  ...,  0.6879,  0.8274,  0.8971],\n",
      "          ...,\n",
      "          [ 0.0953,  0.0431,  0.0431,  ...,  0.1825,  0.2173,  0.2522],\n",
      "          [ 0.1128,  0.0953,  0.1476,  ...,  0.1999,  0.2696,  0.3219],\n",
      "          [ 0.1128,  0.1825,  0.2871,  ...,  0.1825,  0.2348,  0.2348]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0398,  0.0569,  0.1083,  ..., -1.4500, -1.8782, -1.9467],\n",
      "          [ 0.0398,  0.0227,  0.1254,  ..., -1.4158, -1.9638, -1.9467],\n",
      "          [-0.1657,  0.0056,  0.1939,  ..., -1.4843, -1.9295, -1.9295],\n",
      "          ...,\n",
      "          [-0.9363, -1.4500, -1.0904,  ..., -2.1008, -2.0665, -2.0494],\n",
      "          [-0.9705, -1.3130, -1.0390,  ..., -2.1008, -2.0323, -2.0152],\n",
      "          [-0.8507, -1.1075, -0.9363,  ..., -2.0837, -2.0152, -1.9809]],\n",
      "\n",
      "         [[ 0.5728,  0.5903,  0.6779,  ..., -0.3901, -1.0378, -1.3880],\n",
      "          [ 0.5728,  0.5553,  0.6779,  ..., -0.3375, -1.1078, -1.3704],\n",
      "          [ 0.3452,  0.5378,  0.7479,  ..., -0.4251, -1.0903, -1.3529],\n",
      "          ...,\n",
      "          [ 0.1176, -0.3725,  0.0826,  ..., -1.7556, -1.7381, -1.7206],\n",
      "          [ 0.0651, -0.2500,  0.1176,  ..., -1.7906, -1.7206, -1.7206],\n",
      "          [ 0.1352, -0.0749,  0.1877,  ..., -1.7556, -1.7031, -1.6856]],\n",
      "\n",
      "         [[ 1.6291,  1.6465,  1.7337,  ...,  0.6531, -0.0267, -0.3578],\n",
      "          [ 1.6291,  1.6117,  1.7337,  ...,  0.7054, -0.1138, -0.3578],\n",
      "          [ 1.3851,  1.5768,  1.7860,  ...,  0.6182, -0.0790, -0.3578],\n",
      "          ...,\n",
      "          [ 1.5768,  1.1237,  1.5594,  ..., -1.0376, -0.9504, -0.9156],\n",
      "          [ 1.5594,  1.2457,  1.6291,  ..., -1.0724, -0.9504, -0.8981],\n",
      "          [ 1.6814,  1.4548,  1.7163,  ..., -1.0201, -0.9156, -0.8633]]]])\n",
      "y ->  [array([[0.33252 , 0.517019, 0.143555, 0.069249, 1.      ],\n",
      "       [0.327637, 0.421948, 0.143555, 0.062207, 1.      ],\n",
      "       [0.320312, 0.674296, 0.150391, 0.055164, 1.      ],\n",
      "       [0.322754, 0.768192, 0.147461, 0.083333, 1.      ],\n",
      "       [0.322266, 0.864437, 0.140625, 0.073944, 1.      ],\n",
      "       [0.501465, 0.815141, 0.129883, 0.158451, 1.      ],\n",
      "       [0.646973, 0.818075, 0.116211, 0.159624, 1.      ],\n",
      "       [0.14502 , 0.812207, 0.110352, 0.157277, 1.      ],\n",
      "       [0.408462, 0.746696, 0.633877, 0.394894, 5.      ]]), array([[0.856934, 0.354818, 0.131836, 0.43099 , 1.      ],\n",
      "       [0.804199, 0.705078, 0.250977, 0.251302, 1.      ],\n",
      "       [0.728027, 0.349609, 0.125977, 0.43099 , 1.      ]]), array([[0.524041, 0.552556, 0.616274, 0.75806 , 0.      ]]), array([[0.310547, 0.525847, 0.527344, 0.217469, 1.      ],\n",
      "       [0.453613, 0.254011, 0.487305, 0.183601, 1.      ],\n",
      "       [0.451172, 0.130125, 0.464844, 0.156863, 1.      ],\n",
      "       [0.452148, 0.770053, 0.482422, 0.224599, 1.      ],\n",
      "       [0.453613, 0.665775, 0.489258, 0.180036, 1.      ]]), array([[0.55127 , 0.638889, 0.424805, 0.71875 , 2.      ],\n",
      "       [0.166016, 0.641493, 0.326172, 0.706597, 2.      ]]), array([[0.51457 , 0.719727, 0.827815, 0.556641, 2.      ],\n",
      "       [0.522517, 0.231445, 0.870199, 0.388672, 2.      ]]), array([[0.535546, 0.437149, 0.440685, 0.669392, 0.      ]]), array([[0.268555, 0.448529, 0.261719, 0.596639, 1.      ],\n",
      "       [0.549805, 0.459034, 0.359375, 0.69958 , 1.      ]]), array([[0.50293 , 0.525391, 0.416016, 0.076172, 1.      ],\n",
      "       [0.505859, 0.347656, 0.416016, 0.089844, 1.      ],\n",
      "       [0.503906, 0.438477, 0.419922, 0.074219, 1.      ],\n",
      "       [0.493164, 0.435547, 0.914062, 0.310547, 6.      ]]), array([[0.80127 , 0.545898, 0.391602, 0.902344, 0.      ],\n",
      "       [0.308594, 0.52002 , 0.542969, 0.958008, 0.      ]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m): \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e) \n\u001b[1;32m---> 15\u001b[0m     \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_anchors\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Saving the model \u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_model: \n",
      "Cell \u001b[1;32mIn[27], line 17\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(loader, model, optimizer, loss_fn, scaler, scaled_anchors)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx -> \u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my -> \u001b[39m\u001b[38;5;124m\"\u001b[39m, y)\n\u001b[0;32m     16\u001b[0m y0, y1, y2 \u001b[38;5;241m=\u001b[39m ( \n\u001b[1;32m---> 17\u001b[0m     \u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device), \n\u001b[0;32m     18\u001b[0m     y[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m     19\u001b[0m     y[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m     20\u001b[0m ) \n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(): \n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Getting the model predictions \u001b[39;00m\n\u001b[0;32m     24\u001b[0m     feature_map1, feature_map2, feature_map3 \u001b[38;5;241m=\u001b[39m model(x) \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Defining the optimizer \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) \n",
    "  \n",
    "# Defining the loss function \n",
    "loss_fn = YOLOLoss() \n",
    "  \n",
    "# Defining the scaler for mixed precision training \n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "# Training the model \n",
    "for e in range(1, epochs+1): \n",
    "    print(\"Epoch:\", e) \n",
    "    training_loop(dataloaders[\"train\"], model, optimizer, loss_fn, scaler, scaled_anchors) \n",
    "  \n",
    "    # Saving the model \n",
    "    if save_model: \n",
    "        save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2016e-7fa3-4c45-8465-31a76cdca56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
